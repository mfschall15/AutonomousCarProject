{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aItI4pLHbKak"
      },
      "source": [
        "Jetsim : Build Model\n",
        "===\n",
        "\n",
        "### **Step 4.2** from README.md\n",
        "\n",
        "---\n",
        "\n",
        "INITIAL SETUP\n",
        "\n",
        "Right click and open 'this' notebook **JESTIM_interactive_regression.ipynb** in Google colab.\n",
        "\n",
        "Open 'Edit/Notebook settings' toolbar in Google Colab and select **GPU**\n",
        "\n",
        "If you get any runtime errors at anytime, go to 'Runtime' toolbar and click 'Restart Runtime'. Rerun all cells.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "srQXifcZbMN6",
        "outputId": "c6353372-0554-49f1-d544-a94b215a094c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "DONE\n"
          ]
        }
      ],
      "source": [
        "#initialize google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "print(\"DONE\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vefE6hHPT3WH"
      },
      "source": [
        "Select 'jestim-google-colab' dirctory and unzip images\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV55ouL_bSgQ"
      },
      "outputs": [],
      "source": [
        "%cd /content/gdrive/MyDrive/jetsim_googlecolab/SIM_road_following_A\n",
        "!unzip m1_images.zip\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXwBsqODbKan"
      },
      "source": [
        "Task - initialize data set\n",
        "===\n",
        "\n",
        "### Place all name-converted images into 'SIM_road_following_A/apex' folder before running this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBIXWM8ZbKao",
        "outputId": "5efd641c-7092-4ab8-edd2-7a3595fc1528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from xy_dataset import XYDataset\n",
        "\n",
        "#TASK = 'road_following'\n",
        "TASK = 'SIM_road_following'\n",
        "\n",
        "CATEGORIES = ['m1_images']\n",
        "\n",
        "DATASETS = ['A']\n",
        "\n",
        "TRANSFORMS = transforms.Compose([\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.2),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "datasets = {}\n",
        "for name in DATASETS:\n",
        "    datasets[name] = XYDataset(TASK + '_' + name, CATEGORIES, TRANSFORMS, random_hflip=True)\n",
        "\n",
        "print(\"DONE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Vx6c9zbKao"
      },
      "source": [
        "### Data Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "vvmGCl6mbKao",
        "outputId": "1a055ebc-89ac-4b52-d237-9c465bec782d"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1620fbb90a0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gdrive/MyDrive/jetsim_googlecolab/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.485\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.406\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import ipywidgets\n",
        "import traitlets\n",
        "from IPython.display import display\n",
        "\n",
        "# initialize active dataset\n",
        "dataset = datasets[DATASETS[0]]\n",
        "\n",
        "dataset_widget = ipywidgets.Dropdown(options=DATASETS, description='dataset')\n",
        "category_widget = ipywidgets.Dropdown(options=dataset.categories, description='category')\n",
        "count_widget = ipywidgets.IntText(description='count')\n",
        "\n",
        "# manually update counts at initialization\n",
        "count_widget.value = dataset.get_count(category_widget.value)\n",
        "\n",
        "# sets the active dataset\n",
        "def set_dataset(change):\n",
        "    global dataset\n",
        "    dataset = datasets[change['new']]\n",
        "    count_widget.value = dataset.get_count(category_widget.value)\n",
        "dataset_widget.observe(set_dataset, names='value')\n",
        "\n",
        "# update counts when we select a new category\n",
        "def update_counts(change):\n",
        "    count_widget.value = dataset.get_count(change['new'])\n",
        "category_widget.observe(update_counts, names='value')\n",
        "\n",
        "\n",
        "def save_snapshot(_, content, msg):\n",
        "    if content['event'] == 'click':\n",
        "        data = content['eventData']\n",
        "        x = data['offsetX']\n",
        "        y = data['offsetY']\n",
        "        \n",
        "        # save to disk\n",
        "        dataset.save_entry(category_widget.value, camera.value, x, y)\n",
        "        \n",
        "        # display saved snapshot\n",
        "        snapshot = camera.value.copy()\n",
        "        snapshot = cv2.circle(snapshot, (x, y), 8, (0, 255, 0), 3)\n",
        "        snapshot_widget.value = bgr8_to_jpeg(snapshot)\n",
        "        count_widget.value = dataset.get_count(category_widget.value)\n",
        "        \n",
        "# camera_widget.on_msg(save_snapshot)\n",
        "\n",
        "data_collection_widget = ipywidgets.VBox([\n",
        "    dataset_widget,\n",
        "    category_widget,\n",
        "    count_widget\n",
        "])\n",
        "\n",
        "# ipywidgets.HBox([camera_widget, snapshot_widget]),\n",
        "# display(data_collection_widget)\n",
        "\n",
        "# Evalutate stuff, not needed for traing but need for code competion. \n",
        "import threading\n",
        "import time\n",
        "from utils import preprocess\n",
        "import torch.nn.functional as F\n",
        "\n",
        "state_widget = ipywidgets.ToggleButtons(options=['stop', 'live'], description='state', value='stop')\n",
        "\n",
        "def live(state_widget, model, camera, prediction_widget):\n",
        "    global dataset\n",
        "            \n",
        "def start_live(change):\n",
        "  pass\n",
        "\n",
        "print(\"DONE\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkkq6HRTbKap"
      },
      "source": [
        "Setup empty model\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKNZXGCHbKap"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "device = torch.device('cuda')\n",
        "output_dim = 2 * len(dataset.categories)  # x, y coordinate for each category\n",
        "\n",
        "# ALEXNET\n",
        "# model = torchvision.models.alexnet(pretrained=True)\n",
        "# model.classifier[-1] = torch.nn.Linear(4096, output_dim)\n",
        "\n",
        "# SQUEEZENET \n",
        "# model = torchvision.models.squeezenet1_1(pretrained=True)\n",
        "# model.classifier[1] = torch.nn.Conv2d(512, output_dim, kernel_size=1)\n",
        "# model.num_classes = len(dataset.categories)\n",
        "\n",
        "# RESNET 18\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "model.fc = torch.nn.Linear(512, output_dim)\n",
        "\n",
        "# RESNET 34\n",
        "# model = torchvision.models.resnet34(pretrained=True)\n",
        "# model.fc = torch.nn.Linear(512, output_dim)\n",
        "\n",
        "# DENSENET 121\n",
        "# model = torchvision.models.densenet121(pretrained=True)\n",
        "# model.classifier = torch.nn.Linear(model.num_features, output_dim)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model_save_button = ipywidgets.Button(description='save model')\n",
        "model_load_button = ipywidgets.Button(description='load model')\n",
        "model_path_widget = ipywidgets.Text(description='model path', value='NAME.pth')\n",
        "\n",
        "def load_model(c):\n",
        "    model.load_state_dict(torch.load(model_path_widget.value))\n",
        "model_load_button.on_click(load_model)\n",
        "    \n",
        "def save_model(c):\n",
        "    torch.save(model.state_dict(), model_path_widget.value)\n",
        "model_save_button.on_click(save_model)\n",
        "\n",
        "model_widget = ipywidgets.VBox([\n",
        "    model_path_widget,\n",
        "    ipywidgets.HBox([model_load_button, model_save_button])\n",
        "])\n",
        "\n",
        "\n",
        "display(model_widget)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7fHBKI8tjXt"
      },
      "source": [
        "rename model 'NAME.pth' and click SAVE. The click LOAD in the widget above.\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ny-BVRItjXu"
      },
      "source": [
        "Setup training parameters\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sri2bsmYbKar"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n",
        "\n",
        "epochs_widget = ipywidgets.IntText(description='epochs', value=10)\n",
        "eval_button = ipywidgets.Button(description='evaluate')\n",
        "train_button = ipywidgets.Button(description='train')\n",
        "loss_widget = ipywidgets.FloatText(description='loss')\n",
        "progress_widget = ipywidgets.FloatProgress(min=0.0, max=1.0, description='progress')\n",
        "\n",
        "def train_eval(is_training):\n",
        "    global BATCH_SIZE, LEARNING_RATE, MOMENTUM, model, dataset, optimizer, eval_button, train_button, accuracy_widget, loss_widget, progress_widget, state_widget\n",
        "    \n",
        "    try:\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        state_widget.value = 'stop'\n",
        "        train_button.disabled = True\n",
        "        eval_button.disabled = True\n",
        "        time.sleep(1)\n",
        "\n",
        "        if is_training:\n",
        "            model = model.train()\n",
        "        else:\n",
        "            model = model.eval()\n",
        "\n",
        "        while epochs_widget.value > 0:\n",
        "            i = 0\n",
        "            sum_loss = 0.0\n",
        "            error_count = 0.0\n",
        "            for images, category_idx, xy in iter(train_loader):\n",
        "                # send data to device\n",
        "                images = images.to(device)\n",
        "                xy = xy.to(device)\n",
        "\n",
        "                if is_training:\n",
        "                    # zero gradients of parameters\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                # execute model to get outputs\n",
        "                outputs = model(images)\n",
        "\n",
        "                # compute MSE loss over x, y coordinates for associated categories\n",
        "                loss = 0.0\n",
        "                for batch_idx, cat_idx in enumerate(list(category_idx.flatten())):\n",
        "                    loss += torch.mean((outputs[batch_idx][2 * cat_idx:2 * cat_idx+2] - xy[batch_idx])**2)\n",
        "                loss /= len(category_idx)\n",
        "\n",
        "                if is_training:\n",
        "                    # run backpropogation to accumulate gradients\n",
        "                    loss.backward()\n",
        "\n",
        "                    # step optimizer to adjust parameters\n",
        "                    optimizer.step()\n",
        "\n",
        "                # increment progress\n",
        "                count = len(category_idx.flatten())\n",
        "                i += count\n",
        "                sum_loss += float(loss)\n",
        "                progress_widget.value = i / len(dataset)\n",
        "                loss_widget.value = sum_loss / i\n",
        "                \n",
        "            if is_training:\n",
        "                epochs_widget.value = epochs_widget.value - 1\n",
        "            else:\n",
        "                break\n",
        "    except e:\n",
        "        pass\n",
        "    model = model.eval()\n",
        "\n",
        "    train_button.disabled = False\n",
        "    eval_button.disabled = False\n",
        "    state_widget.value = 'live'\n",
        "    \n",
        "train_button.on_click(lambda c: train_eval(is_training=True))\n",
        "eval_button.on_click(lambda c: train_eval(is_training=False))\n",
        "    \n",
        "train_eval_widget = ipywidgets.VBox([\n",
        "    epochs_widget,\n",
        "    progress_widget,\n",
        "    loss_widget,\n",
        "    ipywidgets.HBox([train_button, eval_button])\n",
        "])\n",
        "\n",
        "#display(train_eval_widget)\n",
        "\n",
        "print(\"DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZsHXIuMbKas"
      },
      "outputs": [],
      "source": [
        "all_widget = ipywidgets.VBox([\n",
        "    ipywidgets.HBox([data_collection_widget]), train_eval_widget,\n",
        "    model_widget\n",
        "])\n",
        "\n",
        "display(all_widget)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXTuQs62tjXw"
      },
      "source": [
        "Epoch and training tips\n",
        "===\n",
        "\n",
        "---\n",
        "\n",
        "- Epochs = 10.\n",
        "- Click 'train' button.\n",
        "- Watch blue progress bar, <5 minutes.\n",
        "- Click 'save model' button when training is finished.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjV0Cdwdjxuh"
      },
      "source": [
        "### Create the **models** folder to store all your models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixYBZlYdZe-2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dir = \"models\"\n",
        "try:\n",
        "    os.makedirs(dir, exist_ok = False)\n",
        "    print(\"Directory '%s' created successfully\" % dir)\n",
        "except OSError as error:\n",
        "    print(\"Directory '%s' already exists\" % dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-fK5Stqkm6N"
      },
      "source": [
        "### Move your 'model.pth' to **models** folder inside Google drive **manually**. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4u6UOmNKZe-2"
      },
      "source": [
        "### Close this notebook and proceed to **step 5** in README.md.\n",
        "\n",
        "### Follow **JETSIM_road_following.ipynb** notbook to test model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMqrbN5Fjm6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}